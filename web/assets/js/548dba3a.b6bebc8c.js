"use strict";(self.webpackChunklasso=self.webpackChunklasso||[]).push([[6035],{3470:(e,n,t)=>{t.r(n),t.d(n,{default:()=>x});var a=t(6540),s=t(4025),i=t(5260),r=t(3551),o=t(7156),l=t(5292),m=t(5430),p=t(4939);class c{static MAP={HELLO_WORLD_QUICKSTART:{label:"Hello World (JDK Collections)",description:"Explore the 'Hello World' quickstart example",lsl:"dataSource 'lasso_quickstart'\nstudy(name: 'HelloWorld') {\n\n    /* create stimulus matrix */\n    action(name: 'create') {\n        execute {\n            // from JDK classes\n            stimulusMatrix('Stack', \"\"\"Stack {\n                    push(java.lang.String)->java.lang.String\n                    size()->int }\"\"\",\n                    [\n                            implementation(\"1\", \"java.util.Stack\"),\n                            implementation(\"2\", \"java.util.ArrayDeque\"),\n                            implementation(\"3\", \"java.util.LinkedList\")\n                    ], [\n                    test(name: 'testPush()') {\n                        row '',    'create', 'Stack'\n                        row '',  'push',   'A1',     '\"Hello World!\"'\n                        row '',  'size',   'A1'\n                    }])\n        }\n    }\n    /* Execute stimulus matrix and obtain stimulus response matrix */\n    action(name: 'filter', type: 'Arena') {\n        dependsOn 'create'\n        include 'Stack'\n        profile('java17Profile') {\n            scope('class') { type = 'class' }\n            environment('java17') {\n                image = 'maven:3.9-eclipse-temurin-17' // docker image (JDK 17)\n            }\n        }\n    }\n}\n            ",srmpath:"/web/srm/HELLO_WORLD_QUICKSTART.parquet",classifier:"quickstart, example"},BASE64_ENCODE_DECODE_MAVEN:{label:"Base64 Encode/Decode (Maven Artifacts)",description:"Explore how Maven artifacts can be used as part of stimulus matrices",lsl:"dataSource 'lasso_quickstart'\nstudy(name: 'Base64encodedecode') {\n\n    action(name: 'create') {\n        execute {\n            // from known maven artifact (assuming maven repository is able to provide the artifact)\n            stimulusMatrix('Base64', \"\"\"Base64{\n                    encode(byte[])->byte[]\n                    decode(java.lang.String)->byte[]\n                }\n                \"\"\", [\n                    implementation(\"1\", \"org.apache.commons.codec.binary.Base64\", \"commons-codec:commons-codec:1.15\"),\n            ], [ // tests\n                 test(name: 'testEncode()') {\n                     row '', 'create', 'Base64'\n                     row '\"dXNlcjpwYXNz\".getBytes()', 'encode', 'A1', '\"user:pass\".getBytes()'\n                 },\n                 test(name: 'testEncode_padding()') {\n                     row '', 'create', 'Base64'\n                     row '\"SGVsbG8gV29ybGQ=\".getBytes()', 'encode', 'A1', '\"Hello World\".getBytes()'\n                 }])\n        }\n    }\n\n    action(name: 'test', type: 'Arena') {\n        features = ['cc'] // enable code coverage measurement (class scope)\n        maxAdaptations = 1 // how many adaptations to try\n\n        dependsOn 'create'\n        include 'Base64'\n        profile('java17Profile') {\n            scope('class') { type = 'class' }\n            environment('java17') {\n                image = 'maven:3.9-eclipse-temurin-17' // docker image (JDK 17)\n            }\n        }\n    }\n}\n            ",srmpath:"/web/srm/BASE64_ENCODE_DECODE_MAVEN.parquet",classifier:"example"},BOUNDED_QUEUE_MUTATION:{label:"Mutation Testing with LASSO",description:"Explore how Mutation Testing can be used. The example demonstrates mutation testing based on an implementation of a bounded queue",lsl:"dataSource 'lasso_quickstart'\nstudy(name: 'BoundedQueue-Mutation') {\n\n    action(name: 'select') {\n        execute {\n            // from JDK classes\n            stimulusMatrix('BoundedQueue', \"\"\"MyBoundedQueue {\n                    MyBoundedQueue(int)\n                    enQueue(java.lang.Object)->void\n                    deQueue()->java.lang.Object\n                    isEmpty()->boolean\n                    isFull()->boolean\n                }\n                \"\"\",\n                    [\n                            implementation(\"1\", \"demo_examples.BoundedQueue\")\n                    ], [\n                    test(name: 'testEnqueue()') {\n                        row '', 'create', 'MyBoundedQueue', '10'\n                        row '', 'enQueue', 'A1', '\"Hello World!\"'\n                        row '', 'isEmpty', 'A1'\n                        row '', 'isFull', 'A1'\n                        row '', 'deQueue', 'A1'\n                        row '', 'isEmpty', 'A1'\n                    }\n            ])\n        }\n    }\n\n    action(name: 'test', type: 'Arena') { // filter by tests\n        adapterStrategy = 'PassThroughAdaptationStrategy'\n        features = [\"mutation\"]\n\n        dependsOn 'select'\n        include 'BoundedQueue'\n        profile('java17Profile') {\n            scope('class') { type = 'class' }\n            environment('java17') {\n                image = 'maven:3.9-eclipse-temurin-17' // docker image (JDK 17)\n            }\n        }\n    }\n}\n            ",srmpath:"/web/srm/BOUNDED_QUEUE_MUTATION.parquet",classifier:"example"},OPENAI_GEN:{label:"Generate with OpenAI gpt4-o-mini",description:"Explore how OpenAI's GPT models can be used with LASSO to prompt for code solutions and tests. The functionality sought after is taken from the HumanEval benchmark (e.g., coding problem HumanEval_13_greatest_common_divisor)",lsl:"dataSource 'lasso_quickstart'\nstudy(name: 'ChatGPT') {\n\n    // load benchmark\n    def humanEval = loadBenchmark(\"humaneval-java-reworded\")\n\n    action(name: \"createStimulusMatrices\") {\n        execute {\n            // create stimulus matrices for given problems\n            def myProblems = [humanEval.abstractions['HumanEval_13_greatest_common_divisor']]\n            myProblems.each { problem ->\n                stimulusMatrix(problem.id, problem.lql, [/*impls*/], problem.tests, problem.dependencies) // id, interface, impls, tests, dependencies\n            }\n        }\n    }\n\n    action(name: 'generateCodeGpt', type: 'GenerateCodeOpenAI') {\n        // pipeline specific\n        dependsOn 'createStimulusMatrices'\n        include '*'\n        profile('java17Profile') // evosuite 11\n\n        // action configuration block\n        apiKey = \"demo\" // see https://docs.langchain4j.dev/integrations/language-models/open-ai/\n        model = \"gpt-4o-mini\"\n        samples = 1\n\n        // custom DSL command offered by the action (for each stimulus matrix, create one prompt to obtain impls)\n        prompt { stimulusMatrix ->\n            // can by for any prompts: FA, impls, models etc.\n            def prompt = [:] // create prompt model\n            prompt.promptContent = \"\"\"implement a java class with the following interface specification, but do not inherit a java interface: ```${stimulusMatrix.lql}```. Only output the java class and nothing else.\"\"\"\n            prompt.id = \"lql_prompt\"\n            return [prompt] // list of prompts is expected\n        }\n    }\n\n    action(name: 'generateTestsGpt', type: 'GenerateTestsOpenAI') {\n        // pipeline specific\n        dependsOn 'generateCodeGpt'\n        include '*'\n        profile('java17Profile')\n\n        // action configuration block\n        apiKey = \"demo\" // see https://docs.langchain4j.dev/integrations/language-models/open-ai/\n        model = \"gpt-4o-mini\"\n        samples = 1\n\n        prompt { stimulusMatrix ->\n            def prompt = [:] // create prompt model\n            prompt.promptContent = \"\"\"generate a junit test class to test the functionality of the following interface specification: ```${stimulusMatrix.lql}```. Assume that the specification is encapsulated in a class that uses the same naming as in the interface specification. Only output the JUnit test class and nothing else.\"\"\"\n            prompt.id = \"lql_prompt\"\n            return [prompt] // list of prompts is expected\n        }\n    }\n\n    action(name: 'execute', type: 'Arena') {\n        maxAdaptations = 1 // how many adaptations to try\n\n        dependsOn 'generateTestsGpt'\n        include '*'\n        profile('java17Profile')\n    }\n}\n            ",srmpath:"/web/srm/OPENAI_GEN.parquet",classifier:"example"},OLLAMA_GEN:{label:"Generate with Ollama (llama3.1)",description:"Explore how Ollama and compatible models can be used with LASSO to prompt for code solutions and tests. The functionality sought after is taken from the HumanEval benchmark (e.g., coding problem HumanEval_13_greatest_common_divisor)",lsl:"dataSource 'lasso_quickstart'\nstudy(name: 'Ollama-Parallel') {\n\n    // profile for execution\n    profile('java17Profile') {\n        scope('class') { type = 'class' }\n        environment('java17') {\n            image = 'maven:3.9-eclipse-temurin-17'\n        }\n    }\n\n    // load benchmark\n    def humanEval = loadBenchmark(\"humaneval-java-reworded\")\n\n    action(name: \"createStimulusMatrices\") {\n        execute {\n            // create stimulus matrices for given problems\n            def myProblems = [humanEval.abstractions['HumanEval_13_greatest_common_divisor']]\n            myProblems.each { problem ->\n                stimulusMatrix(problem.id, problem.lql, [/*impls*/], problem.tests, problem.dependencies) // id, interface, impls, tests, dependencies\n            }\n        }\n    }\n\n    action(name: 'generateCodeLlama', type: 'GenerateCodeOllama') {\n        // pipeline specific\n        dependsOn 'createStimulusMatrices'\n        include '*'\n        profile('java17Profile')\n\n        // action configuration block\n        servers = [\"http://bagdana.informatik.uni-mannheim.de:11434\", \"http://dybbuk.informatik.uni-mannheim.de:11434\"]\n        model = \"llama3.1:latest\"\n        samples = 5 // FIXME how many to sample\n        promptRequestThreads = 4 // parallel threads\n\n        // custom DSL command offered by the action (for each stimulus matrix, create one prompt to obtain impls)\n        prompt { stimulusMatrix ->\n            // can by for any prompts: FA, impls, models etc.\n            def prompt = [:] // create prompt model\n            prompt.promptContent = \"\"\"implement a java class with the following interface specification, but do not inherit a java interface: ```${stimulusMatrix.lql}```. Only output the java class and nothing else.\"\"\"\n            prompt.id = \"lql_prompt\"\n            return [prompt] // list of prompts is expected\n        }\n    }\n\n    action(name: 'generateTestsLlama', type: 'GenerateTestsOllama') {\n        // pipeline specific\n        dependsOn 'generateCodeLlama'\n        include '*'\n        profile('java17Profile')\n\n        // action configuration block\n        servers = [\"http://bagdana.informatik.uni-mannheim.de:11434\", \"http://dybbuk.informatik.uni-mannheim.de:11434\"]\n        model = \"llama3.1:latest\"\n        samples = 10\n        promptRequestThreads = 4 // parallel threads\n\n        prompt { stimulusMatrix ->\n            def prompt = [:] // create prompt model\n            prompt.promptContent = \"\"\"generate a junit test class to test the functionality of the following interface specification: ```${stimulusMatrix.lql}```. Assume that the specification is encapsulated in a class that uses the same naming as in the interface specification. Only output the JUnit test class and nothing else.\"\"\"\n            prompt.id = \"lql_prompt\"\n            return [prompt] // list of prompts is expected\n        }\n    }\n\n    action(name: 'execute', type: 'Arena') { // run all collected stimulus sheets on all impls in arena\n        maxAdaptations = 1 // how many adaptations to try\n\n        dependsOn 'generateTestsLlama'\n        include '*'\n        profile('java17Profile')\n    }\n}\n            ",srmpath:"/web/srm/OLLAMA_GEN.parquet",classifier:"example"},STACK_PARAMETERIZED:{label:"Parameterized Sequence Sheets",description:"Explore how sequence sheets can be parameterized (here using an example of Stack implementations)",lsl:"dataSource 'lasso_quickstart'\n// interface in LQL notation\ndef interfaceSpec = \"\"\"Stack {\n    push(java.lang.String)->java.lang.String\n    size()->int\n}\n\"\"\"\nstudy(name: 'Stack') {\n\n    action(name: 'create') {\n        stimulusMatrix('Stack', interfaceSpec, // abstraction details\n                [ // implementations\n                  implementation(\"1\", \"java.util.Stack\"),\n                  implementation(\"2\", \"java.util.ArrayDeque\"),\n                  implementation(\"3\", \"java.util.LinkedList\")\n                ],\n                [ // tests\n                  test(name: 'testPush()') {\n                      row '', 'create', 'Stack'\n                      row '', 'push', 'A1', '\"Hi\"'\n                      row '', 'size', 'A1'\n                  },\n                  test(name: 'testPushParameterized(p1=java.lang.String)', p1: \"Hello World!\") {\n                      row '', 'create', 'Stack'\n                      row '', 'push', 'A1', '?p1'\n                      row '', 'size', 'A1'\n                  },\n                  test(name: 'testPushParameterized(p1=java.lang.String)', p1: \"Bla blub!\") // e.g., parameterized\n                ]\n        )\n    }\n\n    action(name: 'test', type: 'Arena') { // run all tests\n        maxAdaptations = 1 // how many adaptations to try\n\n        dependsOn 'create'\n        include 'Stack'\n        profile('java17Profile') {\n            scope('class') { type = 'class' }\n            environment('java17') {\n                image = 'maven:3.9-eclipse-temurin-17' // docker image (JDK 17)\n            }\n        }\n    }\n}\n            ",srmpath:"/web/srm/STACK_PARAMETERIZED.parquet",classifier:"example"},STACK_TYPEAWARETEST:{label:"Type-aware Test Mutation",description:"Explore how existing sequence sheets can be mutated",lsl:"dataSource 'lasso_quickstart'\n// interface in LQL notation\ndef interfaceSpec = \"\"\"Stack {\n    push(java.lang.String)->java.lang.String\n    size()->int\n}\n\"\"\"\nstudy(name: 'Stack') {\n\n    profile('java17Profile') {\n        scope('class') { type = 'class' }\n        environment('java17') {\n            image = 'maven:3.9-eclipse-temurin-17' // docker image (JDK 17)\n        }\n    }\n\n    action(name: 'select') {\n        stimulusMatrix('Stack', interfaceSpec, // abstraction details\n                [ // implementations\n                  implementation(\"1\", \"java.util.Stack\"),\n                  implementation(\"2\", \"java.util.ArrayDeque\"),\n                  implementation(\"3\", \"java.util.LinkedList\")\n                ],\n                [ // tests\n                  test(name: 'testPush()') {\n                      row '',  'create', 'Stack'\n                      row '',  'push',   'A1',     '\"Hi\"'\n                      row '',  'size',   'A1'\n                  },\n                  test(name: 'testPushParameterized(p1=java.lang.String)', p1: \"Hello World!\") {\n                      row '',  'create', 'Stack'\n                      row '',  'push',   'A1',     '?p1'\n                      row '',  'size',   'A1'\n                  },\n                  test(name: 'testPushParameterized(p1=java.lang.String)', p1: \"Bla blub!\") // e.g., parameterized\n                ]\n        )\n    }\n\n    action(name: 'typeAware', type: 'TypeAwareMutatorTestGen') { // add more tests\n        noOfTests = 1 // create one mutation per test\n\n        dependsOn 'select'\n        include 'Stack'\n    }\n\n    action(name: 'test', type: 'Arena') { // run all tests\n        maxAdaptations = 1 // how many adaptations to try\n\n        dependsOn 'typeAware'\n        include 'Stack'\n        profile('java17Profile')\n    }\n}\n            ",srmpath:"/web/srm/STACK_TYPEAWARETEST.parquet",classifier:"example"},DGAI_LLM:{label:"Differential GAI with many Test Generators and LLMs (LLAMA and DeepSeek-R1)",description:"Explore how LASSO can be used to realized Differential GAI",lsl:"dataSource 'lasso_quickstart'\nstudy(name: 'DGAI') {\n\n    // profile for execution\n    profile('java17Profile') {\n        scope('class') { type = 'class' }\n        environment('java17') {\n            image = 'maven:3.9-eclipse-temurin-17'\n        }\n    }\n\n    // profile for execution\n    profile('java11Profile') {\n        scope('class') { type = 'class' }\n        environment('java17') {\n            image = 'maven:3.6.3-openjdk-11' // EvoSuite won't run in > JDK 11\n        }\n    }\n\n    // load benchmark\n    def humanEval = loadBenchmark(\"humaneval-java-reworded\")\n\n    action(name: \"createStimulusMatrices\") {\n        execute {\n            // create stimulus matrices for given problems\n            def myProblems = [humanEval.abstractions['HumanEval_13_greatest_common_divisor']]\n            myProblems.each { problem ->\n                stimulusMatrix(problem.id, problem.lql, [/*impls*/], problem.tests) // id, interface, impls, tests\n            }\n        }\n    }\n\n    action(name: 'generateCodeLlama', type: 'GenerateCodeOllama') {\n        // pipeline specific\n        dependsOn 'createStimulusMatrices'\n        include '*'\n        profile('java11Profile') // evosuite 11\n\n        // action configuration block\n        ollamaBaseUrl = \"http://bagdana.informatik.uni-mannheim.de:11434\"\n        model = \"llama3.1:latest\"\n        samples = 10 // how many to sample\n        javaVersion = \"11\" // because of EvoSuite ..\n\n        prompt { stimulusMatrix ->\n            def prompt = [:] // create prompt model\n            prompt.promptContent = \"\"\"implement a java class with the following interface specification, but do not inherit a java interface: ```${stimulusMatrix.lql}```. Only output the java class and nothing else.\"\"\"\n            prompt.id = \"lql_prompt\"\n            return [prompt] // list of prompts is expected\n        }\n    }\n\n    action(name: 'generateCodeDeepSeek', type: 'GenerateCodeOllama') {\n        // pipeline specific\n        dependsOn 'generateCodeLlama'\n        include '*'\n        profile('java11Profile') // evosuite 11\n\n        // action configuration block\n        ollamaBaseUrl = \"http://bagdana.informatik.uni-mannheim.de:11434\"\n        model = \"deepseek-r1:32b\"\n        samples = 10 // how many to sample\n        javaVersion = \"11\" // because of EvoSuite ..\n\n        prompt { stimulusMatrix ->\n            def prompt = [:] // create prompt model\n            prompt.promptContent = \"\"\"implement a java class with the following interface specification, but do not inherit a java interface: ```${stimulusMatrix.lql}```. Only output the java class and nothing else.\"\"\"\n            prompt.id = \"lql_prompt\"\n            return [prompt] // list of prompts is expected\n        }\n    }\n\n    // add tests (mutates existing tests)\n    action(name: 'typeAware', type: 'TypeAwareMutatorTestGen') { // add more tests\n        noOfTests = 1 // create one mutation per test\n\n        dependsOn 'generateCodeDeepSeek'\n        include '*'\n    }\n\n    // add tests: randomly add new\n    action(name: 'random', type: 'RandomTestGen') { // add more tests\n        noOfTests = 5 // create 5 additional random tests\n        shuffleSequence = false\n\n        dependsOn 'typeAware'\n        include '*'\n    }\n\n    action(name: 'generateTestsLlama', type: 'GenerateTestsOllama') {\n        // pipeline specific\n        dependsOn 'random'\n        include '*'\n        profile('java17Profile')\n\n        // action configuration block\n        ollamaBaseUrl = \"http://bagdana.informatik.uni-mannheim.de:11434\"\n        model = \"llama3.1:latest\"\n        samples = 10 // how many to sample\n\n        prompt { stimulusMatrix ->\n            def prompt = [:] // create prompt model\n            prompt.promptContent = \"\"\"generate a junit test class to test the functionality of the following interface specification: ```${stimulusMatrix.lql}```. Assume that the specification is encapsulated in a class that uses the same naming as in the interface specification. Only output the JUnit test class and nothing else.\"\"\"\n            prompt.id = \"lql_prompt\"\n            return [prompt] // list of prompts is expected\n        }\n    }\n\n    action(name: 'generateTestsDeepSeek', type: 'GenerateTestsOllama') {\n        // pipeline specific\n        dependsOn 'generateTestsLlama'\n        include '*'\n        profile('java17Profile')\n\n        // action configuration block\n        ollamaBaseUrl = \"http://bagdana.informatik.uni-mannheim.de:11434\"\n        model = \"deepseek-r1:32b\"\n        samples = 10 // how many to sample\n\n        prompt { stimulusMatrix ->\n            def prompt = [:] // create prompt model\n            prompt.promptContent = \"\"\"generate a junit test class to test the functionality of the following interface specification: ```${stimulusMatrix.lql}```. Assume that the specification is encapsulated in a class that uses the same naming as in the interface specification. Only output the JUnit test class and nothing else.\"\"\"\n            prompt.id = \"lql_prompt\"\n            return [prompt] // list of prompts is expected\n        }\n    }\n\n    // add tests: SBST\n    action(name: 'evoSuite', type: 'EvoSuite') {\n        searchBudget = 60 // we need this as upper bound for timeouts\n        stoppingCondition = \"MaxTime\"\n        //criterion = \"LINE:BRANCH:EXCEPTION:WEAKMUTATION:OUTPUT:METHOD:METHODNOEXCEPTION:CBRANCH\"\n        cleanExecutables = false\n\n        dependsOn 'generateTestsDeepSeek'\n        include '*'\n        profile('java11Profile')\n    }\n\n    action(name: 'execute', type: 'Arena') { // run all collected stimulus sheets in arena\n        maxAdaptations = 1 // how many adaptations to try\n        //features = [\"cc\", \"mutation\"]\n\n        dependsOn 'evoSuite'\n        include '*'\n        profile('java17Profile')\n    }\n}\n            ",srmpath:"/web/srm/DGAI.parquet",classifier:"dgai, example"},BENCHMARK_CODELLM:{label:"Replication of HumanEval-J/MBPP-J Benchmark",description:"Explore how LASSO can be used to replicate studies and reuse their designs, here based on the example of HumanEval-J (MultiPL-E)",lsl:"dataSource 'lasso_quickstart'\nstudy(name: 'HumanEval-OriginalPrompt-ShowCode') {\n\n    // profile for execution\n    profile('java17Profile') {\n        scope('class') { type = 'class' }\n        environment('java17') {\n            image = 'maven:3.9-eclipse-temurin-17'\n        }\n    }\n\n    // load benchmark\n    def humanEval = loadBenchmark(\"humaneval-java-reworded\")\n    def mbpp = loadBenchmark(\"mbpp-java-reworded\")\n\n    action(name: \"createStimulusMatrices\") {\n        execute {\n            // create stimulus matrices for given problems\n            humanEval.abstractions.values().each { problem ->\n                stimulusMatrix(problem.id, problem.lql, [/*impls*/], problem.tests, problem.dependencies) // id, interface, impls, tests, dependencies\n            }\n\n            mbpp.abstractions.values().each { problem ->\n                stimulusMatrix(problem.id, problem.lql, [/*impls*/], problem.tests, problem.dependencies) // id, interface, impls, tests, dependencies\n            }\n        }\n    }\n\n    action(name: 'generateCodeLlama', type: 'GenerateCodeOllama') {\n        // pipeline specific\n        dependsOn 'createStimulusMatrices'\n        include '*'\n        profile('java17Profile')\n\n        // action configuration block \n        servers = [\"http://bagdana.informatik.uni-mannheim.de:11434\", \"http://dybbuk.informatik.uni-mannheim.de:11434\"]\n        model = \"llama3.1:latest\"\n        samples = 10 // how many to sample\n        javaVersion = \"17\" // because of EvoSuite ..\n\n        promptRequestThreads = 4 // parallel threads\n\n        prompt { stimulusMatrix ->\n            def prompt = [:] // create prompt model\n            // get original prompt from benchmark\n            prompt.promptContent = humanEval.abstractions[stimulusMatrix.name].prompt\n            prompt.id = \"lql_prompt\"\n            return [prompt] // list of prompts is expected\n        }\n    }\n\n    action(name: 'measureCoverage', type: 'Arena') { // run all collected stimulus sheets in arena\n        maxAdaptations = 1 // how many adaptations to try\n        features = [\"cc\"]\n\n        dependsOn 'generateCodeLlama'\n        include '*'\n        profile('java17Profile')\n    }\n\n    action(name: 'generateTestsLlama', type: 'GenerateTestsOllama') {\n        // pipeline specific\n        dependsOn 'measureCoverage'\n        include '*'\n        profile('java17Profile')\n\n        // action configuration block \n        servers = [\"http://bagdana.informatik.uni-mannheim.de:11434\", \"http://dybbuk.informatik.uni-mannheim.de:11434\"]\n        model = \"llama3.1:latest\"\n        samples = 1 // how many to sample\n        promptRequestThreads = 4 // parallel threads\n\n        prompt { stimulusMatrix ->\n            List prompts = stimulusMatrix.implementations.collect { impl ->\n                def prompt = [:] // create prompt model\n                prompt.promptContent = \"\"\"generate a junit test class to test the functionality of the following java class `${impl.code.name}` : ```${impl.code.content}```. Initialize the class and call its methods. Only output the JUnit test class and nothing else.\"\"\"\n                prompt.id = \"lql_prompt\"\n                return prompt\n            }\n\n            return prompts\n        }\n    }\n\n    action(name: 'execute', type: 'Arena') { // run all collected stimulus sheets in arena\n        maxAdaptations = 1 // how many adaptations to try\n        features = [\"cc\"]\n\n        dependsOn 'generateTestsLlama'\n        include '*'\n        profile('java17Profile')\n    }\n}\n            ",srmpath:"/web/srm/HUMANEVAL.parquet",classifier:"benchmark, replication, humaneval, mbpp, example"}}}var d=t(8553),u=t(7669),h=t(5e3),f=t(1543),A=t(5610),S=t(1978),E=t(3984),v=t(5281),b=t(4335),g=t(4848);const T=e=>{let{fileName:n}=e;const[t,s]=(0,a.useState)(),[i,o]=(0,a.useState)(),[c,u]=(0,a.useState)(""),[T,x]=(0,a.useState)("Select * from tdse_srm.parquet"),y=(0,a.useRef)(),[j,D]=(0,a.useState)([]),[w,I]=(0,a.useState)([]),O=(0,a.useRef)(null),M=(0,a.useRef)(null),k=async(e,t,a)=>{if(O.current&&O.current.getModel().setValue(a),!y.current){const e=A.vP(),t=await A.DF(e),a=URL.createObjectURL(new Blob([`importScripts("${t.mainWorker}");`],{type:"text/javascript"})),s=new Worker(a),i=new A.Cr,r=new A.Ed(i,s);await r.instantiate(t.mainModule,t.pthreadWorker),URL.revokeObjectURL(a);const o={query:{castBigIntToDouble:!0}};r.open(o),console.log("loaded duckdb");let l=(await b.A.get(`${n}`,{responseType:"arraybuffer"})).data;await r.registerFileBuffer("tdse_srm.parquet",new Uint8Array(await l)),console.log("registered parquet file"),y.current=r}const s=await y.current.connect(),i=(await s.query(`\n        ${a}\n    `)).toArray().map((e=>e.toJSON())),r=Object.keys(i[0]).map((e=>({field:e,headerName:e,width:150})));I(r);D(i),await s.close()},_=e=>{k(0,0,e),x(e)},C=e=>{let n;n=e?`PIVOT (SELECT SHEETID, X, Y, CONCAT(SYSTEMID,'_',VARIANTID,'_',ADAPTERID) as SYSTEMID, value from tdse_srm.parquet where type = '${e}') ON SYSTEMID USING first(VALUE) ORDER BY SHEETID, X, Y`:"PIVOT (SELECT SHEETID, X, Y, CONCAT(SYSTEMID,'_',VARIANTID,'_',ADAPTERID) as SYSTEMID, value, type from tdse_srm.parquet) ON SYSTEMID USING first(VALUE) ORDER BY SHEETID, X, Y",x(n),k(0,0,n)};return(0,g.jsxs)(a.Fragment,{children:[(0,g.jsx)(r.A,{variant:"h6",component:"div",children:"Explore SRM data using duckdb in your browser"}),(0,g.jsxs)(l.A,{children:[(0,g.jsx)(r.A,{gutterBottom:!0,sx:{color:"text.secondary",fontSize:18},children:"SQL (duckdb-wasm)"}),(0,g.jsx)(r.A,{variant:"h5",component:"div",children:(0,g.jsx)(d.KE,{height:"100px",defaultLanguage:"sql",defaultValue:T,onMount:function(e,n){n.languages.register({id:"sql"}),M.current=n,O.current=e},onChange:(e,n)=>{e&&x(e)}})})]}),(0,g.jsx)(m.A,{}),(0,g.jsxs)(h.A,{variant:"contained","aria-label":"Basic button group",children:[(0,g.jsx)(p.A,{onClick:e=>{k(0,0,"Select * from tdse_srm.parquet")},children:"Load Raw SRM parquet"}),(0,g.jsx)(p.A,{onClick:e=>(k(0,0,T),void x(T)),children:"Query SQL"}),(0,g.jsx)(p.A,{onClick:e=>_("select SHEETID from tdse_srm.parquet group by SHEETID order by SHEETID"),children:"Show Tests"}),(0,g.jsx)(p.A,{onClick:e=>_("select SHEETID, X, Y from tdse_srm.parquet where X >= 0 and Y >= 0 group by SHEETID, X, Y order by SHEETID, X, Y"),children:"Show Test Statements"}),(0,g.jsx)(p.A,{onClick:e=>_("select SYSTEMID from tdse_srm.parquet where SYSTEMID != 'abstraction' and SYSTEMID != 'oracle' group by SYSTEMID"),children:"Show Compilation Units"}),(0,g.jsx)(p.A,{onClick:e=>_("select SYSTEMID, VARIANTID, ADAPTERID from tdse_srm.parquet where SYSTEMID != 'abstraction' and SYSTEMID != 'oracle' group by SYSTEMID, VARIANTID, ADAPTERID"),children:"Show Executed Implementations"}),(0,g.jsx)(p.A,{onClick:e=>C("value"),children:"View Outputs"}),(0,g.jsx)(p.A,{onClick:e=>C("service"),children:"View Services"}),(0,g.jsx)(p.A,{onClick:e=>C("input_value"),children:"View Inputs"}),(0,g.jsx)(p.A,{onClick:e=>C("op"),children:"View Operations"}),(0,g.jsx)(p.A,{onClick:e=>C(void 0),children:"View All"})]}),(0,g.jsx)(f.A,{}),(0,g.jsxs)(h.A,{variant:"contained","aria-label":"Basic button group",children:[(0,g.jsx)(p.A,{onClick:e=>_("select count(*) as cluster_size, list(SYSTEMID) as cluster_implementations, * EXCLUDE (SYSTEMID) from (PIVOT (SELECT CONCAT(SHEETID,'@',X, ',', Y) as statement, CONCAT(SYSTEMID,'_',VARIANTID,'_',ADAPTERID) as SYSTEMID, value from tdse_srm.parquet where type = 'value') ON STATEMENT USING first(VALUE) ORDER BY SYSTEMID) as mypiv group by all order by cluster_size DESC"),children:"Cluster-based Voting"}),(0,g.jsx)(p.A,{onClick:e=>_("select count(*) as cluster_size, list(SYSTEMID) as cluster_implementations, * EXCLUDE (SYSTEMID) from (PIVOT (SELECT CONCAT(SHEETID,'@',X, ',', Y) as statement, CONCAT(SYSTEMID,'_',VARIANTID,'_',ADAPTERID) as SYSTEMID, value from tdse_srm.parquet where type = 'value' and y > 0) ON STATEMENT USING first(VALUE) ORDER BY SYSTEMID) as mypiv group by all order by cluster_size DESC"),children:"Cluster-based Voting (Ignore Create)"})]}),(0,g.jsx)(f.A,{}),(0,g.jsxs)(h.A,{variant:"contained","aria-label":"Basic button group",children:[(0,g.jsx)(p.A,{onClick:e=>_("\n-- pick oracle based on test-based voting (based on mode; most frequent value per test statement)\nSelect \n    ABSTRACTIONID,\n    SHEETID,\n    X,\n    Y,\n    MODE(VALUE) as test_based_oracle,\n    list(DISTINCT VALUE) as distinct_values,\n    (select list(CONCAT(SYSTEMID, '_', VARIANTID, '_', ADAPTERID) ORDER BY SYSTEMID, VARIANTID, ADAPTERID) from tdse_srm.parquet where VALUE = test_based_oracle and TYPE = 'value' and ABSTRACTIONID = tbl1.ABSTRACTIONID and SHEETID = tbl1.SHEETID and X = tbl1.X and Y=tbl1.Y) as matches\nfrom tdse_srm.parquet as tbl1 where TYPE = 'value' and SYSTEMID != 'oracle' GROUP BY ABSTRACTIONID, SHEETID, X, Y ORDER BY SHEETID, X, Y\n              "),children:"Test-based Oracle"}),(0,g.jsx)(p.A,{onClick:e=>_("\n-- pick oracle based on test-based voting (based on mode; most frequent value per test statement)\nSelect \n    ABSTRACTIONID,\n    SHEETID,\n    X,\n    Y,\n    MODE(VALUE) as test_based_oracle,\n    list(DISTINCT VALUE) as distinct_values,\n    (select list(CONCAT(SYSTEMID, '_', VARIANTID, '_', ADAPTERID) ORDER BY SYSTEMID, VARIANTID, ADAPTERID) from tdse_srm.parquet where VALUE = test_based_oracle and TYPE = 'value' and ABSTRACTIONID = tbl1.ABSTRACTIONID and SHEETID = tbl1.SHEETID and X = tbl1.X and Y=tbl1.Y) as matches\nfrom tdse_srm.parquet as tbl1 where TYPE = 'value' and SYSTEMID != 'oracle' and Y > 0 GROUP BY ABSTRACTIONID, SHEETID, X, Y ORDER BY SHEETID, X, Y\n              "),children:"Test-based Oracle (Ignore Create)"})]}),(0,g.jsx)(f.A,{}),(0,g.jsx)(v.A,{target:"_blank",href:n,children:"Download Raw Parquet"}),(0,g.jsx)(f.A,{}),(0,g.jsx)("div",{style:{height:"500px",width:"100%"},children:(0,g.jsx)(S.z,{slots:{toolbar:E.O},rows:j,columns:w,getRowId:e=>Math.floor(1e8*Math.random())})})]})},x=()=>{const[e,n]=(0,a.useState)(""),[t,h]=(0,a.useState)(!1),[f,A]=(0,a.useState)(!1),S=(0,a.useRef)(null),E=(0,a.useRef)(null);return(0,g.jsxs)(s.A,{children:[(0,g.jsxs)(i.A,{children:[(0,g.jsx)("title",{children:"TDSE Hub"}),(0,g.jsx)("meta",{name:"description",content:"A hub for TDSEs"})]}),(0,g.jsxs)(r.A,{sx:{margin:2},variant:"h5",component:"div",children:["TDSEHub",(0,g.jsx)(r.A,{variant:"h6",component:"div",children:"Explore LSL Pipelines and their SRMs"})]}),(0,g.jsxs)(u.A,{container:!0,spacing:2,children:[(0,g.jsx)(u.A,{size:3,children:Object.keys(c.MAP).map((e=>(0,g.jsx)(g.Fragment,{children:(0,g.jsxs)(o.A,{sx:{minWidth:275,margin:2},children:[(0,g.jsxs)(l.A,{children:[(0,g.jsx)(r.A,{variant:"h5",component:"div",children:c.MAP[e].label}),(0,g.jsx)(r.A,{sx:{color:"text.secondary",mb:1.5},children:c.MAP[e].classifier}),(0,g.jsx)(r.A,{variant:"body2",children:c.MAP[e].description})]}),(0,g.jsxs)(m.A,{children:[(0,g.jsx)(p.A,{onClick:t=>{return n(a=e),h(!0),A(!1),S.current&&S.current.getModel().setValue(c.MAP[a].lsl),void window.scrollTo({top:0,left:0});var a},size:"small",children:"Show LSL Pipeline"}),(0,g.jsx)(p.A,{onClick:t=>{return n(a=e),h(!1),A(!0),S.current&&S.current.getModel().setValue(c.MAP[a].lsl),void window.scrollTo({top:0,left:0});var a},size:"small",children:"Analyze SRM"})]})]})})))}),(0,g.jsxs)(u.A,{size:9,children:[e?(0,g.jsx)(r.A,{sx:{margin:2},variant:"h5",component:"div",children:(0,g.jsxs)(r.A,{variant:"h6",component:"div",children:["Study '",c.MAP[e].label,"'"]})}):null,t?(0,g.jsxs)(g.Fragment,{children:[(0,g.jsxs)(l.A,{children:[(0,g.jsxs)(r.A,{sx:{margin:2},variant:"h5",component:"div",children:["LSL Pipeline Viewer",(0,g.jsx)(r.A,{variant:"h6",component:"div",children:"Explore the study and actions"})]}),(0,g.jsx)(r.A,{variant:"h5",component:"div",children:(0,g.jsx)(d.KE,{height:"500px",defaultLanguage:"java",defaultValue:c.MAP[e].lsl,onMount:function(e,n){n.languages.register({id:"java"}),E.current=n,S.current=e}})})]}),(0,g.jsx)(m.A,{})]}):null,f?(0,g.jsx)(T,{fileName:c.MAP[e].srmpath}):null]})]})]})}}}]);